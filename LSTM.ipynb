{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYxHIGN9zzlh",
        "outputId": "2a90b279-341d-4e38-9a66-ef614b6b6dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 205ms/step\n",
            "Predictions:\n",
            "[[18.849411]]\n",
            "MEAN SQUARED ERROR 1066.4988675572083\n",
            "ROOT MEAN SQUARED ERROR:  32.65729424733789\n",
            "MEAN ABSOLUTE ERROR:  32.65729424733789\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Load the datasets\n",
        "patterns_df = pd.read_csv('patterns.csv')\n",
        "requests_df = pd.read_csv('requests.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "# Assuming the 'Pattern' column contains the sequences to be used for training the LSTM\n",
        "# Convert the 'Pattern' column to a list of lists\n",
        "patterns_df['Pattern'] = patterns_df['Pattern'].apply(eval)\n",
        "\n",
        "# Convert categorical data to numerical data\n",
        "encoder = LabelEncoder()\n",
        "patterns_df['Pattern'] = patterns_df['Pattern'].apply(lambda x: encoder.fit_transform(x))\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "patterns_df['Pattern'] = patterns_df['Pattern'].apply(lambda x: scaler.fit_transform(np.array(x).reshape(-1, 1)))\n",
        "\n",
        "# Pad the sequences to have the same length\n",
        "patterns_list = patterns_df['Pattern'].tolist()\n",
        "patterns_list = pad_sequences(patterns_list, dtype='float32', padding='post')\n",
        "\n",
        "# Reshape the input into the form [samples, time steps, features]\n",
        "patterns = np.array(patterns_list).reshape(-1, patterns_list.shape[1], 1)\n",
        "\n",
        "# Assuming the 'Rack_id' and 'Datanode' columns are to be used for prediction\n",
        "encoder.fit(list(patterns_df['Rack_id'].unique()) + list(patterns_df['Datanode'].unique()))\n",
        "patterns_df['Rack_id'] = encoder.transform(patterns_df['Rack_id']).astype(np.int32)\n",
        "patterns_df['Datanode'] = encoder.transform(patterns_df['Datanode']).astype(np.int32)\n",
        "\n",
        "# Define the LSTM Model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(patterns_list.shape[1], 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Assuming the 'Frequency' column is the target variable\n",
        "target = patterns_df['Rack_id'].values\n",
        "\n",
        "# Train the model\n",
        "model.fit(patterns, target, epochs=200, verbose=0)\n",
        "\n",
        "# Preprocess the test data\n",
        "num_samples = len(list(set(requests_df['Rack_id'])) + list(set(requests_df['Datanode'])))\n",
        "requests = np.array(list(set(requests_df['Rack_id'])) + list(set(requests_df['Datanode'])))\n",
        "requests = requests.reshape(-1, 1)\n",
        "\n",
        "\n",
        "# Preprocess the test data\n",
        "unique_rack_ids_requests = np.unique(requests_df['Rack_id']).astype(str)\n",
        "unique_rack_ids_patterns = np.unique(patterns_df['Rack_id']).astype(str)\n",
        "# Add 'R' prefix to rack IDs in patterns_df\n",
        "# Convert rack IDs to strings before adding prefix\n",
        "patterns_df['Rack_id'] = 'R' + patterns_df['Rack_id'].astype(str)\n",
        "\n",
        "# Filter unique_rack_ids to only include rack IDs present in patterns_df_grouped\n",
        "patterns_df_grouped = patterns_df.groupby('Rack_id')['Frequency'].mean().reset_index()\n",
        "common_rack_ids = np.intersect1d(unique_rack_ids_requests, patterns_df_grouped['Rack_id'].astype(str))\n",
        "\n",
        "if len(common_rack_ids) == 0:\n",
        "    raise ValueError(\"No common rack IDs present in both requests_df and patterns_df_grouped.\")\n",
        "\n",
        "# Create a dummy input for the model to predict\n",
        "dummy_input = np.repeat(encoder.transform(common_rack_ids)[:, None, None], 14, axis=1)\n",
        "\n",
        "# Normalize the input data\n",
        "dummy_input = scaler.transform(dummy_input.reshape(-1, 1))\n",
        "\n",
        "# Reshape the input data for the model\n",
        "dummy_input = dummy_input.reshape(len(common_rack_ids), 14, 1)\n",
        "\n",
        "# Use the model to predict the test data\n",
        "predictions = model.predict(dummy_input)\n",
        "print(\"Predictions:\")\n",
        "print(predictions)\n",
        "# Calculate the actual values for the test data\n",
        "actual_values = patterns_df_grouped.loc[patterns_df_grouped['Rack_id'].astype(str).isin(common_rack_ids), 'Frequency'].values\n",
        "\n",
        "# Calculate the Mean Squared Error\n",
        "mse = mean_squared_error(actual_values, predictions.flatten())\n",
        "\n",
        "# Calculate the Root Mean Squared Error\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "mae = mean_absolute_error(actual_values, predictions.flatten())\n",
        "print(\"MEAN SQUARED ERROR\",mse)\n",
        "print(\"ROOT MEAN SQUARED ERROR: \",rmse)\n",
        "print(\"MEAN ABSOLUTE ERROR: \",mae)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uem79UVGy1ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BW4kW9yqy1hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P2aBGnn_y1lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O6zsR3nZy1oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a1q5hy-Ly1rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b04M7uj3y1uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b5_vay_Xy2cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GE0y9EY3y2fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I4R1gfvsy2hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XQN8yR7ay2k5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}